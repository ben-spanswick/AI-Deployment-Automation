version: '3.8'

services:
  localai:
    image: quay.io/go-skynet/local-ai:latest-gpu-nvidia-cuda-12
    container_name: localai
    ports:
      - "8080:8080"
    volumes:
      - /opt/ai-box/localai:/build/models
      - models-data:/tmp/generated
    environment:
      - THREADS=8
      - DEBUG=false
      - CUDA_VISIBLE_DEVICES=0,1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1']
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - ai-network

  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    ports:
      - "5678:5678"
    volumes:
      - /home/mandrake/ai-box-data/n8n:/home/node/.n8n
    environment:
      - WEBHOOK_URL=http://localhost:5678/
      - GENERIC_TIMEZONE=America/New_York
    user: "1000:1000"
    restart: unless-stopped
    networks:
      - ai-network

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - /opt/ai-box/ollama:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - CUDA_VISIBLE_DEVICES=0,1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1']
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - ai-network

  dcgm:
    image: nvcr.io/nvidia/k8s/dcgm-exporter:3.1.8-3.1.5-ubuntu20.04
    container_name: dcgm
    ports:
      - "9400:9400"
    environment:
      - DCGM_EXPORTER_LISTEN=0.0.0.0:9400
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: all
    restart: unless-stopped
    networks:
      - ai-network

  chromadb:
    image: chromadb/chroma:latest
    container_name: chromadb
    ports:
      - "8000:8000"
    volumes:
      - chromadb-data:/chroma/chroma
    environment:
      - CUDA_VISIBLE_DEVICES=0,1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1']
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - ai-network

  dashboard:
    image: nginx:alpine
    container_name: dashboard
    ports:
      - "80:80"
    volumes:
      - /opt/ai-box/nginx/html:/usr/share/nginx/html:ro
      - /opt/ai-box/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    restart: unless-stopped
    networks:
      - ai-network

  comfyui:
    image: yanwk/comfyui-boot:latest
    container_name: comfyui
    ports:
      - "8188:8188"
    volumes:
      - /opt/ai-box/comfyui:/workspace
      - /opt/ai-box/models:/workspace/models
      - /opt/ai-box/comfyui/output:/workspace/output
      - /usr/local/cuda-12.1/lib64:/usr/local/cuda/lib64:ro
    environment:
      - CLI_ARGS=--listen --port 8188
      - CUDA_VISIBLE_DEVICES=0,1
      - LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
      - CUDA_HOME=/usr/local/cuda
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1']
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - ai-network

  whisper:
    image: onerahmet/openai-whisper-asr-webservice:latest-gpu
    container_name: whisper
    ports:
      - "9000:9000"
    volumes:
      - /opt/ai-box/whisper:/app/cache
    environment:
      - ASR_MODEL=small
      - CUDA_VISIBLE_DEVICES=0,1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1']
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - ai-network

  forge:
    image: nykk3/stable-diffusion-webui-forge:latest
    container_name: forge
    ports:
      - "1111:7860"
    volumes:
      - /opt/ai-box/models/stable-diffusion:/app/stable-diffusion-webui/models/Stable-diffusion
      - /opt/ai-box/models/loras:/app/stable-diffusion-webui/models/Lora
      - /opt/ai-box/models/vae:/app/stable-diffusion-webui/models/VAE
      - /opt/ai-box/outputs/forge:/app/stable-diffusion-webui/outputs
      - /opt/ai-box/forge-extensions:/app/stable-diffusion-webui/extensions
      - /usr/local/cuda-12.1/lib64:/usr/local/cuda/lib64:ro
      - /usr/local/cuda-12.1/compat:/usr/local/cuda/compat:ro
    environment:
      - COMMANDLINE_ARGS=--listen --api --xformers --medvram --skip-torch-cuda-test --skip-version-check --no-download-sd-model
      - CUDA_VISIBLE_DEVICES=1
      - LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/compat:$LD_LIBRARY_PATH
      - CUDA_HOME=/usr/local/cuda
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      - TORCH_CUDA_ARCH_LIST=8.6;8.9
      - CUDA_MODULE_LOADING=LAZY
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['1']
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - ai-network
    shm_size: 8gb

networks:
  ai-network:
    driver: bridge
    name: ai-network
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  models-data:
    driver: local
  chromadb-data:
    driver: local
  comfyui-data:
    driver: local